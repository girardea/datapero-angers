{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MANUela Anomaly ML Model\n",
    "\n",
    "(original source available at: https://github.com/sa-mw-dach/manuela-dev/blob/master/ml-models/anomaly-detection/Anomaly-Detection-simple-ML-Training.ipynb)\n",
    "\n",
    "Goal: Build a machine lerning model that detects anomalies in sensor vibration data\n",
    "\n",
    "![anomalies](https://raw.githubusercontent.com/sa-mw-dach/manuela/master/docs/images/manuela-anomalies.png)\n",
    "\n",
    "**Outline:**\n",
    "\n",
    "### Read and preview the labeled data\n",
    "- Read data from disk\n",
    "- Preview the raw data\n",
    "- Visualize vibration and anomalies\n",
    "\n",
    "### Data wrangling\n",
    "- Convert time series data into small episodes that can be used for supervised learning.\n",
    "- Explore the new data format\n",
    "\n",
    "### Model training\n",
    "- Prepare the data for modeling, training and testing\n",
    "- Train and validate model\n",
    "\n",
    "### Save the new model\n",
    "- Save model to disk\n",
    "- Commit and push to git\n",
    "\n",
    "###  Model serving during runtime\n",
    "- View the warpper code for the model serving with Seldon\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('raw-data.csv')\n",
    "df['time'] = pd.to_datetime(df['ts'],unit='ms')\n",
    "df.set_index('time', inplace=True)\n",
    "df.drop(columns=['ts'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview the raw data\n",
    "Quick view on the data. It is a dataframe with a \n",
    "- timeseries, \n",
    "- an id for the pump, \n",
    "- the vibration value\n",
    "- and a label indicating an anmonaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize data\n",
    "- The uppper graph show a subset of the vibration data.\n",
    "- The lower graph illustrates the anomalies (1 = anomaly, 0 = normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df21 = df.head(100)\n",
    "df21.plot(figsize=(20,10), fontsize=12,subplots=True, style=[\"-\",\"o\"], title = \"Pump 2 - 100 Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "Goal: Convert time series data into small episodes that can be uses for supervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Few helper functions\n",
    "#\n",
    "\n",
    "# Get list with column names: F1, F2, Fn, L\n",
    "def get_columns(n):\n",
    "    f = []\n",
    "    for x in range(1,n+1):\n",
    "        f.append(\"F\"+str(x))\n",
    "    f.append(\"L\")\n",
    "    return f\n",
    "\n",
    "# Create empty data frame\n",
    "def create_empty_df(n):\n",
    "    d= ([0.]*n)\n",
    "    d.append(0)\n",
    "    dfx = pd.DataFrame([d], columns=get_columns(n))\n",
    "    dfx.drop(dfx.index[0], inplace=True)\n",
    "    return dfx\n",
    "\n",
    "# Create data frame with one row\n",
    "def create_df(vals: list, label: int = 0):\n",
    "    if not isinstance(vals, list):\n",
    "        raise TypeError\n",
    "    #vals.append(label)    \n",
    "    dfx = pd.DataFrame([vals+[label]], columns=get_columns(len(vals)))\n",
    "    return dfx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "Create a new dataframe: Rows represent the last x (length) value and the label.\n",
    "\n",
    "\n",
    "```\n",
    "| tz | value | label |\n",
    "|----|-------|-------|\n",
    "| .. |   ... |   .   |\n",
    "| 04 |   6.2 |   0   |\n",
    "| 05 |   7.2 |   0   |\n",
    "| 06 |   5.1 |   0   |\n",
    "| 07 |   6.4 |   0   |\n",
    "| 08 |   2.2 |   0   |\n",
    "| 09 |  12.4 |   0   |\n",
    "| 10 |   8.4 |   1   |\n",
    "| .. |   ... |   .   |\n",
    "```\n",
    "\n",
    "Convert to episodes with lenght = 5\n",
    "\n",
    "```\n",
    "\n",
    "| F1 | F2 | F3 | F4 | F5 |  L  |\n",
    "|----|----|----|----|----|---- |\n",
    "| 6.2| 7.2| 5.1| 6.4| 2.2|  0  |\n",
    "| 7.2| 5.1| 6.4| 2.2|12.4|  1  |\n",
    "| 5.1| 6.4| 2.2|12.4| 8.4|  0  |\n",
    "\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 5 # Episode lenght\n",
    "\n",
    "df_epis = create_empty_df(length)\n",
    "\n",
    "for id in df.id.unique():\n",
    "    print(\"Convert data for: \", id)\n",
    "    \n",
    "    df2 = df.loc[df['id'] == id]\n",
    "\n",
    "    epi = []\n",
    "    for index, row in df2.iterrows():\n",
    "        # print('%6.2f, %d' % (row['value'], row['label']))\n",
    "        epi.append(row['value'])\n",
    "        if len(epi) == length :\n",
    "            df_row = create_df(epi,row['label'] )\n",
    "            df_epis = df_epis.append(df_row, ignore_index=True)\n",
    "            del(epi[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the new data format\n",
    "Show episodes of the lengh 5 and the label in the last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_epis.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is ready for supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data for modeling, training and testing\n",
    "- Identify and separate the feature and target columns\n",
    "- Training and Testing Data Split\n",
    "\n",
    "### Identify feature and target columns\n",
    "Like many ML libraries, sklern requires separted feature (X) and target (Y) columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature columns\n",
    "feature_cols = list(df_epis.columns[:-1])\n",
    "\n",
    "# Extract target column 'label'\n",
    "target_col = df_epis.columns[-1] \n",
    "\n",
    "# Show the list of columns\n",
    "print (\"Feature columns:\\n{}\".format(feature_cols))\n",
    "print (\"\\nTarget column: {}\".format(target_col))\n",
    "\n",
    "# Separate the data into feature data and target data (X_all and y_all, respectively)\n",
    "X_all = df_epis[feature_cols]\n",
    "y_all = df_epis[target_col]\n",
    "\n",
    "# Show the feature information by printing the first five rows\n",
    "print (\"\\nFeature values:\")\n",
    "print (X_all.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing Data Split\n",
    "It is best best practise to have separate sets for the training and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X_all, y_all, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "# Show the results of the split\n",
    "print (\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print (\"Testing set has {} samples.\".format(X_test.shape[0]))\n",
    "\n",
    "print (\"Anomaly rate of the training set: {:.2f}%\".format(100 * (y_train == 1).mean()))\n",
    "print (\"Anomaly rate of the testing set: {:.2f}%\".format(100 * (y_test == 1).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "Let's do a quick model training with a Decision Tree Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "my_random_seed = 42\n",
    "\n",
    "# Initialize the DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(random_state=my_random_seed)\n",
    "\n",
    "# train the classifier\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict with the test data\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "# Determine the accuracy score\n",
    "accuracy_score = accuracy_score(y_test, y_predict)\n",
    "\n",
    "print (\"Accuracy score for the trained model: {:.4f}.\".format(accuracy_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... the accuracy is pretty good.\n",
    "\n",
    "\n",
    "### Save model to disk\n",
    "- Save the model\n",
    "- Load the model again and check that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "filename = 'model.joblib'\n",
    "dump(model, open(filename, 'wb'))\n",
    "\n",
    "# Validate that the model can be loaded\n",
    "\n",
    "# load the model from disk\n",
    "loaded_model = load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test, y_test)\n",
    "print(\"Score:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commit the new model to git\n",
    "The new model is saved in git so that the Tekton pipeline can build a new container image with the model\n",
    "```\n",
    "git add model.joblib\n",
    "git commit -m \"Update ML model\"\n",
    "pit push\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model serving during runtime\n",
    "Have a look here to view the warpper code for the model serving with Seldon [AnomalyDetection.py](https://github.com/sa-mw-dach/manuela-dev/blob/master/components/iot-anomaly-detection/AnomalyDetection.py#L11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
